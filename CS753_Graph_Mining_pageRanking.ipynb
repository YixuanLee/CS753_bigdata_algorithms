{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f38c3086",
   "metadata": {},
   "source": [
    "<h1> CS753 Assignment 3 Graph Mining Algorithms</h1>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a808993e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee44eb77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total number of links:  5105039\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "data = np.loadtxt(r'....web-Google.txt',dtype= int)\n",
    "print (\"total number of links: \", len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099f84a",
   "metadata": {},
   "source": [
    "<h3>Task 1: Implementation of Power Iteration Algorithm.</h3> \n",
    "\n",
    "<h4>(a) Implement the power iteration algorithm in matrix form without teleport (on slides page 20): Let stop criteria be ||r (t+1) − r (t) ||1 < 0.02. Spider traps and dead ends are not considered in this task [30 pts].</h4>\n",
    "    \n",
    "<h4> <font color='blue'>Total number of unique source nodes is 739454. Because of big data nature, we use sparsematrix to store the adjacency matrix. In order to put source nodes as column and destinations as rows, I did a transpose before matrix multiplication with initial votes. The convergence happens when newrank - oldrank smaller than a threshold 0.02. Results show the column sum of sparseMatrix </font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "70e9aaca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique source nodes:  739454\n",
      "column sum of sparse matrix : [[1. 1. 1. ... 1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# get counts of repetitive source nodes\n",
    "\n",
    "source,ind,counts = np.unique(data[:,0],return_inverse=True, return_counts=True)\n",
    "print(\"Total unique source nodes: \", len(source))\n",
    "# get initial votes for each node\n",
    "\n",
    "votes = 1/counts[ind]        \n",
    "\n",
    "# size of sparse matrix\n",
    "SM_size = max(max(data[:,0]),max(data[:,1]))+1\n",
    "# creating sparse matrix\n",
    "sparseMatrix = csr_matrix((votes, (data[:,0], data[:,1])), \n",
    "                          shape = (SM_size, SM_size))\n",
    "\n",
    "# initialize ranks\n",
    "rank = np.ones((SM_size,1))/SM_size\n",
    "# Power iteration algorithm\n",
    "t1 = time.time()\n",
    "flag = True\n",
    "n=0\n",
    "while flag:\n",
    "    n += 1\n",
    "    sparseMatrix_t = sparseMatrix.transpose() # transpose sparseMatrix to destination as rows and source as columns\n",
    "    newrank = sparseMatrix_t.dot(rank)\n",
    "    #Stop condition\n",
    "    if np.linalg.norm(rank-newrank,ord=1)<0.02:\n",
    "        flag = False        \n",
    "    rank = newrank \n",
    "t2 = time.time()\n",
    "\n",
    "## column sum of sparsematrix\n",
    "\n",
    "colsum = sparseMatrix_t.sum(axis=0)\n",
    "\n",
    "print(\"column sum of sparse matrix :\", colsum)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdc379bc",
   "metadata": {},
   "source": [
    "<h4>(b) Calculate the rank score for all the nodes and report: (1) The running time of your power iteration algorithm; (2) the number of iterations needed to stop; (3) the IDs and scores of the top-10 ranked nodes [10 pts].</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ddd2e816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time is  1748 ms\n",
      "Total number of iterations till convergence :  62\n",
      "IDs and scores of the top-10 ranked nodes:  [(6116, 0.0006177867154815842), (69056, 0.0006065543233976054), (69055, 0.0006065543233976054), (69057, 0.0006065543233976054), (31563, 0.00038756780164943863), (572672, 0.0003482264479290426), (572673, 0.00030958996008457015), (60232, 0.00027105054535807397), (572674, 0.0002702807179711503), (33676, 0.00025978830964025945)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total running time is \",round((t2-t1)*1000), \"ms\")\n",
    "print(\"Total number of iterations till convergence : \", n)\n",
    "\n",
    "top10_rank = np.sort(np.squeeze(rank))[::-1]\n",
    "top10_node = np.argsort(np.squeeze(rank))[::-1]\n",
    "print(\"IDs and scores of the top-10 ranked nodes: \", list(zip(top10_node[0:10],top10_rank[0:10])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b030af1a",
   "metadata": {},
   "source": [
    "<h3>2.Task 2: Exploiting dead-ends:</h3>\n",
    "\n",
    "<h4>Before extending your codes to support dead ends, let’s first do some analysis on your current implementation in Task1. Report the leaked PageRank score in each iteration of task 1 and explain the phenomenon you observe from the above experiments.</h4>\n",
    "\n",
    "<h4><font color='blue'> According to the result shown underlying, rating scores of dead-end nodes are continuously reducing over 20 iterations, indicating the pageRank scores are leaked through the dead-end nodes. In addition, the indices of dead-end nodes and total number of dead-end nodes are reported. The sum of final total rankings after convergence is 0.193, << 1,giving further evidence of pageRank leaking.  </font></h4>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20664fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "indices of dead-end nodes:  [    17     33     35 ... 875702 875706 875707]\n",
      "total number of dead-end nodes:  136259\n"
     ]
    }
   ],
   "source": [
    "nodes_deadend = np.where(colsum==0)[1]\n",
    "print(\"indices of dead-end nodes: \", nodes_deadend)\n",
    "print(\"total number of dead-end nodes: \", len(nodes_deadend))\n",
    "\n",
    "# get counts of repetitive source nodes\n",
    "\n",
    "source,ind,counts = np.unique(data[:,0],return_inverse=True, return_counts=True)\n",
    "\n",
    "# get initial votes for each node\n",
    "\n",
    "votes = 1/counts[ind]        \n",
    "\n",
    "# size of sparse matrix\n",
    "SM_size = max(max(data[:,0]),max(data[:,1]))+1\n",
    "# creating sparse matrix\n",
    "sparseMatrix = csr_matrix((votes, (data[:,0], data[:,1])),shape = (SM_size, SM_size))\n",
    "\n",
    "# initialize ranks\n",
    "rank = np.ones((SM_size,1))/SM_size\n",
    "    \n",
    "flag = True\n",
    "n=0\n",
    "epsilon = 0.02\n",
    "while flag:\n",
    "    print()\n",
    "    n += 1\n",
    "    sparseMatrix_t = sparseMatrix.transpose()\n",
    "    newrank = sparseMatrix_t.dot(rank)\n",
    "    leakedrank= 1-sum(newrank)\n",
    "    while n <=20:\n",
    "        print(\"iteration n: \",n, \"leaded ranking: \", leakedrank)\n",
    "    #Stop condition\n",
    "    if np.linalg.norm(rank-newrank,ord=1)<epsilon:\n",
    "        flag = False\n",
    "    rank = newrank\n",
    "print(\"Sum of total rankings after convergence : \", sum(rank))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e90d77",
   "metadata": {},
   "source": [
    "<h3>3. Task 3: Implementation of Teleport.</h3>\n",
    "\n",
    "<h4>(a) Extend your PageRank code to handle both spider traps and dead ends using the idea of teleport. Let β = 0.9 by default and the stop criteria be ||r(t+1) −r(t)||1 <0.02. </h4>\n",
    "\n",
    "<h4> <font color='blue'>Firstly all rank score would muptiply beta value, 0.9. The value of (1 - sum of all rank scores) is calculated and evenly added back into the new ranking scores. The purpose of doing it is to teleport the leaking scores back to the total network and ensure the column sum is still equal to 1 as shown underlying.</font></h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0d4e38e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Sum of total ranking after teleport :  [1.]\n"
     ]
    }
   ],
   "source": [
    "# get counts of repetitive source nodes\n",
    "source,ind,counts = np.unique(data[:,0],return_inverse=True, return_counts=True)\n",
    "\n",
    "# get initial votes for each node\n",
    "\n",
    "votes = 1/counts[ind]        \n",
    "\n",
    "# size of sparse matrix\n",
    "SM_size = max(max(data[:,0]),max(data[:,1]))+1\n",
    "# creating sparse matrix\n",
    "sparseMatrix = csr_matrix((votes, (data[:,0], data[:,1])),shape = (SM_size, SM_size))\n",
    "# Power iteration algorithm with teleportation\n",
    "t = time.time()\n",
    "def pRank_tele(beta):\n",
    "    # initialize ranks\n",
    "    rank = np.ones((SM_size,1))/SM_size\n",
    "    epsilon = 0.02\n",
    "    flag = True\n",
    "    n=0\n",
    "    while flag:\n",
    "        print()\n",
    "        n += 1\n",
    "        sparseMatrix_t = sparseMatrix.transpose() # transpose sparseMatrix to destination as rows and source as columns\n",
    "        newrank1 = (sparseMatrix_t.dot(rank))*beta\n",
    "        # teleport leaked pagerank\n",
    "        newrank2 = newrank1 + (1-newrank1.sum())/SM_size\n",
    "        #Stop condition\n",
    "        if np.linalg.norm(rank-newrank2,ord=1)<epsilon:\n",
    "            flag = False        \n",
    "        rank = newrank2\n",
    "    return (n,rank)\n",
    "teleRank = pRank_tele(0.9)\n",
    "print(\" Sum of total ranking after teleport : \", sum(teleRank[1]))\n",
    "t_end = time.time()  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a107e224",
   "metadata": {},
   "source": [
    "<h4>(b) Run your code on the Google web data and report: (1) the running time; (2) the\n",
    "number of iterations needed to stop; (3) the IDs and scores of the top-10 ranked\n",
    "nodes [10 pts].</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d6d02c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total running time is:  1791 ms\n",
      "Total number of iterations till convergence :  11\n",
      "IDs and scores of the top-10 ranked nodes after teleport:  [(2138, 0.0010085161582659716), (115, 0.0009705537443270651), (3178, 0.0009380557550726863), (2560, 0.0009314724701097537), (1950, 0.0008509553126824594), (1181, 0.0008113770426201482), (903, 0.0007834380557670724), (1611, 0.00075737276793708), (3150, 0.0007537883564045684), (3180, 0.0007401293020022142)]\n"
     ]
    }
   ],
   "source": [
    "print(\"Total running time is: \",round((t2-t1)*1000), \"ms\")\n",
    "print(\"Total number of iterations till convergence : \", teleRank[0])\n",
    "top_rank = np.sort(np.squeeze(teleRank[1]))[::-1]\n",
    "top_node = np.argsort(np.squeeze(teleRank[1]))[::-1]\n",
    "print(\"IDs and scores of the top-10 ranked nodes after teleport: \", list(zip(top_node[0:10],top_rank[0:10])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a313c",
   "metadata": {},
   "source": [
    "<h4>(c) By varying the teleport probability β in [1, 0.9, 0.8, 0.7, 0.6, 0.5], report the num\u0002ber of iterations needed to stop for each β. Explain your findings from this\n",
    "experiment [10 pts].</h4>\n",
    "\n",
    "<h4> <font color='blue'> From results shown underlying, we can see with decreasing beta value, the total number of iterations is also reduced. The total iterations at beta =1 is 90, which is different from the result obtained previously 62. The reason is when without teleport, it is not actual convergence. The total sum reduced (0.19 << 1) due to ranking score leakage. Therefore when the difference of ranking below threshold (epsilon 0.02), it reached so-called convergence due to the diminishing scores. When teleport is implemented, the convergence is the real convergence because the total sum of the final ranking score is 1, there is no leakage of scores.</font> </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fc2220d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 1 Number of iterations : 90\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 0.9 Number of iterations : 11\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 0.8 Number of iterations : 7\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 0.7 Number of iterations : 6\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 0.6 Number of iterations : 5\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "when beta = 0.5 Number of iterations : 4\n"
     ]
    }
   ],
   "source": [
    "for beta in  [1, 0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "    N_iter = pRank_tele(beta)[0]\n",
    "    print(\"when beta =\", beta,\"Number of iterations :\", N_iter)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
