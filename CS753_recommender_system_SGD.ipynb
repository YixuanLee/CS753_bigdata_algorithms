{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52f7c828",
   "metadata": {},
   "source": [
    "<h1> CS753 Assignment 4 Recommender Systems</h1>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb169dad",
   "metadata": {},
   "source": [
    "<h4>1. Reading json files: https://www.geeksforgeeks.org/read-json-file-using-python/ </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3c05c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from pandas.api.types import CategoricalDtype\n",
    "from scipy import sparse\n",
    "import random\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc783b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. of train:  841020 No. of validation:  8582 No. of test:  8582\n",
      "shape of sparseMatrix:  (41701, 7965) ; total unique user_id:  41701 ; total unique business_id:  7965\n",
      "shape of matrix train, val and test:  (41701, 7965) (41701, 7965) (41701, 7965)\n"
     ]
    }
   ],
   "source": [
    "# load data using Python JSON module\n",
    "train = pd.read_json (r'...train.json', lines=True)\n",
    "train['type']='train'\n",
    "val = pd.read_json (r'...val.json', lines=True)\n",
    "val['type']='val'\n",
    "test = pd.read_json (r'...test.json', lines=True)\n",
    "test['type']='test'\n",
    "print (\"No. of train: \", len(train), \"No. of validation: \", len(val), \"No. of test: \", len(test))\n",
    "\n",
    "# obtain unique values of business_id and user_id in all dataset\n",
    "all = pd.concat([train,val,test])\n",
    "all_user = all['user_id'].unique()\n",
    "all_business = all['business_id'].unique()\n",
    "shape =(len(all_user),len(all_business))\n",
    "print(\"shape of sparseMatrix: \", shape, \"; total unique user_id: \",len(all['user_id'].unique()), \n",
    "      \"; total unique business_id: \", len(all['business_id'].unique()))\n",
    "# Create indices for users and businesses in train dataset\n",
    "user_cat = CategoricalDtype(categories=sorted(all_user), ordered=True)\n",
    "business_cat = CategoricalDtype(categories=sorted(all_business), ordered=True)\n",
    "user_index_train = train[\"user_id\"].astype(user_cat).cat.codes\n",
    "business_index_train = train[\"business_id\"].astype(business_cat).cat.codes\n",
    "user_index_val = val[\"user_id\"].astype(user_cat).cat.codes\n",
    "business_index_val = val[\"business_id\"].astype(business_cat).cat.codes\n",
    "user_index_test = test[\"user_id\"].astype(user_cat).cat.codes\n",
    "business_index_test = test[\"business_id\"].astype(business_cat).cat.codes\n",
    "\n",
    "# create sparse matrix for train, val and test\n",
    "csc_train = sparse.csc_matrix((train[\"stars\"], (user_index_train, business_index_train)), shape=shape)\n",
    "csc_val = sparse.csc_matrix((val[\"stars\"], (user_index_val, business_index_val)), shape=shape)\n",
    "csc_test = sparse.csc_matrix((test[\"stars\"], (user_index_test, business_index_test)), shape=shape)\n",
    "print(\"shape of matrix train, val and test: \" ,csc_train.shape,csc_test.shape,csc_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2921510",
   "metadata": {},
   "source": [
    "<h4>1. Task 1: Estimate the global bias bg, user specific bias b(user)i and item specific bias b(item)j on the training data. Report the global bg, the user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q” , item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”. [10 pts] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f4eb9a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Global bias bg:  3.829\n",
      "The user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q\":  0.0\n",
      "The item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”:  0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ylive\\anaconda3\\lib\\site-packages\\numpy\\matrixlib\\defmatrix.py:193: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  out = N.ndarray.__getitem__(self, index)\n"
     ]
    }
   ],
   "source": [
    "# global bias bg,  user bias bi and item bias bj for training data\n",
    "\n",
    "bg = csc_train.sum()/csc_train.count_nonzero()\n",
    "bi = csc_train.sum(axis =1)/csc_train.astype(bool).sum(axis=1).sum()\n",
    "bj = (csc_train.sum(axis =0)/csc_train.astype(bool).sum(axis=0).sum()).T\n",
    "\n",
    "print(\"Global bias bg: \", round(bg,3))\n",
    "#print(bi.shape, \"user specific bias bi: \", bi)\n",
    "#print(bj.shape, \"item specific bias bj: \", bj)\n",
    "\n",
    "# get index for specific user and business\n",
    "bi_index = np.where(user_cat.categories == 'b4aIMeXOx4cn3bjtdIOo6Q')\n",
    "bi_bias = np.squeeze(bi[[bi_index]]).item()\n",
    "bj_index = np.where(business_cat.categories == '7VQYoXk3Tc8EZeKuXeixeg')\n",
    "bj_bias = np.squeeze(bj[[bj_index]]).item()\n",
    "\n",
    "#print(bi_index,bj_index)\n",
    "print('The user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q\": ', round(bi_bias,3))\n",
    "print('The item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”: ', round(bj_bias,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48940137",
   "metadata": {},
   "source": [
    "<h4>2. Task 2: Implement the basic latent factor model without considering the bias: rij =qTi dot pj. Set the number of latent factors k = 8. Run Stochastic Gradient Descent (SGD) for 10 epoches with a fixed learning rate η = 0.01 and regularization hyperparameter λ1 = λ2 = 0.3. Report the RMSE on the training data for each epoch. [30 pts]</h4>\n",
    "\n",
    "<h5> The result shows RMSE is reducing with the increasing of epoch number, it shows the error is approach local minima</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f439636",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE:  4.044\n",
      "At Epoch  1 , RMSE:  2.579\n",
      "At Epoch  2 , RMSE:  1.324\n",
      "At Epoch  3 , RMSE:  1.185\n",
      "At Epoch  4 , RMSE:  1.156\n",
      "At Epoch  5 , RMSE:  1.145\n",
      "At Epoch  6 , RMSE:  1.14\n",
      "At Epoch  7 , RMSE:  1.137\n",
      "At Epoch  8 , RMSE:  1.135\n",
      "At Epoch  9 , RMSE:  1.133\n",
      "At Epoch  10 , RMSE:  1.132\n"
     ]
    }
   ],
   "source": [
    "## function for calculating RMSE\n",
    "def GD_RMSE(RR,Q,P):\n",
    "    rows,columns,values = sparse.find(RR)\n",
    "    e = 0\n",
    "    size = len(values)\n",
    "    for i,j,v in zip(rows,columns,values):\n",
    "        e= e + pow(v-np.dot(Q[i,:],P[j,:]),2)\n",
    "    rmse_gd = np.sqrt(e/size)\n",
    "    return(rmse_gd)\n",
    "\n",
    "## function for stochastic gradient descent model\n",
    "# R:csc sparse matrix; K:latent factor, lr: learning rate, lamda1 lamda2: hyperparameters\n",
    "def SGD(R,K = 8, lr = 0.01, lamda1 =0.3, lamda2=0.3, epoch = 10 ): \n",
    "    rows,columns,values = sparse.find(R) \n",
    "    #  Latent Factor matrix shape\n",
    "    M,N = R.shape\n",
    "    # using random values of Q and P initialized with normal distribution at mean 0, SD 0.15 and 0.1 with values between [-1.1]\n",
    "    Q=np.random.normal(0, 0.15, M*K).reshape((M,K)) # user factor matrix\n",
    "    P=np.random.normal(0, 0.1, N*K).reshape((N,K)) # business factor matrix\n",
    "    # calculate initial RMSE\n",
    "    rmse1 = GD_RMSE(R,Q,P)\n",
    "    print(\"Initial RMSE: \", round(rmse1,3))\n",
    "    for e in range(0,epoch):\n",
    "        for i,j,v in zip(rows, columns, values): # for each rating of user i and business j\n",
    "            r_hat = np.dot(Q[i,:],P[j,:])           # get rating prediction\n",
    "            for f in range(0,K):\n",
    "                loss_q = -2*(v - r_hat)*P[j,f] + 2*lamda1 * Q[i,f]\n",
    "                loss_p = -2*(v - r_hat)*Q[i,f] + 2*lamda2 * P[j,f]\n",
    "                Q[i,f] -= lr * loss_q\n",
    "                P[j,f] -= lr * loss_p\n",
    "        rmse2 = GD_RMSE(R,Q,P)\n",
    "        print(\"At Epoch \",e+1 ,\", RMSE: \", round(rmse2,3))\n",
    "    return(Q,P)\n",
    "## Run stochastic gradient descent on training data for 10 epoches \n",
    "SGD_train = SGD(csc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb39fd00",
   "metadata": {},
   "source": [
    "<h4>3. Task 3: Use SGD to train the latent factor model with different values of k in {4, 8, 16}\n",
    "and stop after 10 epoches. Report the RMSE for each value of k on the validation\n",
    "data (“val.json”). Pick the model that results in the best RMSE on the validation\n",
    "set and report its RMSE on the test data (“test.json”). [15 pts] </h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "918fe3e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " when k =  4  RMSE is : 1.582\n",
      " when k =  8  RMSE is : 1.59\n",
      " when k =  16  RMSE is : 1.584\n"
     ]
    }
   ],
   "source": [
    "# R:csc sparse matrix; K:latent factor, lr: learning rate, lamda1 lamda2: hyperparameters\n",
    "def SGD_train(R,K = 8, lr = 0.01, lamda1 =0.3, lamda2=0.3, epoch = 10 ): \n",
    "    rows,columns,values = sparse.find(R) \n",
    "    #  Latent Factor matrix shape\n",
    "    M,N = R.shape\n",
    "    # using random values of Q and P \n",
    "    Q=np.random.normal(0, 0.15, M*K).reshape((M,K)) # user factor matrix\n",
    "    P=np.random.normal(0, 0.1, N*K).reshape((N,K)) # business factor matrix\n",
    "    for e in range(0,epoch):\n",
    "        for i,j,v in zip(rows, columns, values): # for each rating of user i and business j\n",
    "            r_hat = np.dot(Q[i,:],P[j,:])           # get rating prediction\n",
    "            for f in range(0,K):\n",
    "                loss_q = -2*(v - r_hat)*P[j,f] + 2*lamda1 * Q[i,f]\n",
    "                loss_p = -2*(v - r_hat)*Q[i,f] + 2*lamda2 * P[j,f]\n",
    "                Q[i,f] -= lr * loss_q\n",
    "                P[j,f] -= lr * loss_p\n",
    "    return(Q,P)\n",
    "\n",
    "## Using Q,P obtained from training data to calculate RMSE on validation data for k = [4,8,16]\n",
    "## to choose the best k at minimum RMSE\n",
    "result =[]\n",
    "for i in [4,8,16]:\n",
    "    result.append(i)\n",
    "    sgdmatrix = SGD_train(csc_train, K = i)\n",
    "    # get RMSE on validation data\n",
    "    RMSE = GD_RMSE(csc_val,sgdmatrix[0],sgdmatrix[1])\n",
    "    result.append(RMSE)\n",
    "    print(\" when k = \", i, \" RMSE of validation dataset is :\" , round(RMSE,3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c83fee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " The best RMSE is:  1.582  when k =  4\n"
     ]
    }
   ],
   "source": [
    "# keep result in 3X2 array\n",
    "result_RMSE = np.asarray(result).reshape((3,2))\n",
    "# get k of mininum RMSE\n",
    "best_k = int(np.squeeze(result_RMSE[np.where(result_RMSE[:,1] ==result_RMSE[:,1].min(axis=0)),0]).item())\n",
    "print(\" The best RMSE is: \",round(result_RMSE[:,1].min(axis=0),3), \" when k = \", best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6a3064",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE on test data is:  1.677\n"
     ]
    }
   ],
   "source": [
    "## Using best k for testing data (csc_test)\n",
    "sgdmatrix_test =SGD_train(csc_train, K = best_k)\n",
    "RMSE_test = GD_RMSE(csc_test,sgdmatrix_test[0],sgdmatrix_test[1])\n",
    "print(\" RMSE o test data is: \", round(RMSE_test,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4668ac25",
   "metadata": {},
   "source": [
    "<h5> Result shows test RMSE is slight higher than the validation error and worse than the training data. This is expected. </h5>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3e2db",
   "metadata": {},
   "source": [
    "<h4>4. Task 4: Incorporate the bias terms bg, b(user)i and b(item)jto the latent factor model:rij = bg + b(user)i + b(item)j + qTipj and learn the user bias and business bias from data.Initialize the user bias b(user)i and item bias terms b(item)j using the values computed in Task 1. Set the number of latent factors k = 8. Run SGD for 10 epoches with a fixed learning rate η = 0.01 and regularization hyperparameter λ1 = λ2 = λ3 = λ4 = 0.3.Report the RMSE on the training data for each epoch and the learned bias terms.[30 pts]</h4>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e681d13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial RMSE:  1.3\n",
      "At Epoch  1 , RMSE:  1.132\n",
      "At Epoch  2 , RMSE:  1.128\n",
      "At Epoch  3 , RMSE:  1.128\n",
      "At Epoch  4 , RMSE:  1.128\n",
      "At Epoch  5 , RMSE:  1.128\n",
      "At Epoch  6 , RMSE:  1.128\n",
      "At Epoch  7 , RMSE:  1.127\n",
      "At Epoch  8 , RMSE:  1.127\n",
      "At Epoch  9 , RMSE:  1.127\n",
      "At Epoch  10 , RMSE:  1.127\n",
      "the user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q\":  -3.957\n",
      " item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”:  -3.626\n"
     ]
    }
   ],
   "source": [
    "## function for calculating RMSE\n",
    "def RMSE_bias(RR,Q,P,bg,bi,bj):\n",
    "    rows,columns,values = sparse.find(RR)\n",
    "    e = 0\n",
    "    size = len(values)\n",
    "    for i,j,v in zip(rows,columns,values):\n",
    "        e= e + pow(v-np.dot(Q[i,:],P[j,:])-bg-bi[i,0]-bj[j,0],2)\n",
    "    rmse = np.sqrt(e/size)\n",
    "    return(rmse)\n",
    "# SGD function with bias # R:csc sparse matrix; K:latent factor, lr: learning rate, lamda1,2,3,4: hyperparameters\n",
    "def SGD_bias(R,K = 8, lr = 0.01, lamda1 =0.3, lamda2=0.3,lamda3 =0.3,lamda4=0.3, epoch = 10 ): \n",
    "    #  Latent Factor matrix shape\n",
    "    M,N = R.shape\n",
    "    # claculate bg, bi (item bias) and bj (business bias)\n",
    "    bg = R.sum()/R.count_nonzero()\n",
    "    bj_val = (R.sum(axis =0)/R.astype(bool).sum(axis=0).sum()).T\n",
    "    bi_val = R.sum(axis =1)/R.astype(bool).sum(axis=1).sum()\n",
    "    bi = np.asarray(bi_val).reshape((M,1))\n",
    "    bj = np.asarray(bj_val).reshape((N,1))\n",
    "    \n",
    "    # get rows,columns,values of non-zero values\n",
    "    rows,columns,values = sparse.find(R) \n",
    "\n",
    "    # using random values of Q and P \n",
    "    Q=np.random.normal(0, 0.15, M*K).reshape((M,K)) # user factor matrix\n",
    "    P=np.random.normal(0, 0.1, N*K).reshape((N,K)) # business factor matrix\n",
    "    # calculate initial RMSE\n",
    "    rmse1 = RMSE_bias(R,Q,P,bg,bi,bj)\n",
    "    print(\"Initial RMSE: \", round(rmse1,3))\n",
    "    for e in range(0,epoch):\n",
    "        for i,j,v in zip(rows, columns, values): # for each rating of user i and business j\n",
    "            r_hat = np.dot(Q[i,:],P[j,:])           # get rating prediction\n",
    "            ## calculate loss function for Q,P, bi and bj\n",
    "            for f in range(0,K):\n",
    "                loss_q = -2*(v - r_hat-bg-bi[i,0]-bj[j,0])*P[j,f] + 2*lamda1 * Q[i,f]\n",
    "                loss_p = -2*(v - r_hat-bg-bi[i,0]-bj[j,0])*Q[i,f] + 2*lamda2 * P[j,f]\n",
    "                loss_bi = -2*(v - r_hat-bg-bi[i,0]-bj[j,0]) + 2*lamda3 * bi[i,0]\n",
    "                loss_bj = -2*(v - r_hat-bg-bi[i,0]-bj[j,0]) + 2*lamda4 * bj[j,0]\n",
    "                Q[i,f] -= lr * loss_q\n",
    "                P[j,f] -= lr * loss_p\n",
    "                bi[i,0] -= lr* loss_bi\n",
    "                bj[j,0] -= lr* loss_bj\n",
    "        rmse2 = RMSE_bias(R,Q,P,bg,bi,bj)\n",
    "        print(\"At Epoch \",e+1 ,\", RMSE: \", round(rmse2,3))\n",
    "    return(Q,P,bi,bj,bg)\n",
    "SGDbias_train = SGD_bias(csc_train)\n",
    "# get index for specific user and business\n",
    "bg = SGDbias_train[4]\n",
    "bi_index = np.where(user_cat.categories == 'b4aIMeXOx4cn3bjtdIOo6Q')\n",
    "bi_bias_SGD = np.squeeze(SGDbias_train[2][bi_index,0]).item()\n",
    "bj_index = np.where(business_cat.categories == '7VQYoXk3Tc8EZeKuXeixeg')\n",
    "bj_bias_SGD = np.squeeze(SGDbias_train[3][bj_index,0]).item()\n",
    "# claculate specific user bias by bi - bg, same for business bias by bj - bg\n",
    "print('the user specific bias of the user with user id= “b4aIMeXOx4cn3bjtdIOo6Q\": ', round(bi_bias_SGD - bg ,3))\n",
    "print(' item specific bias of the business with business id = “7VQYoXk3Tc8EZeKuXeixeg”: ', round(bj_bias_SGD - bg ,3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2261bfd2",
   "metadata": {},
   "source": [
    "<h4>5. Task 5: Similar to Task 3, find the best k on the validation set and apply the corresponding model to the test data. Compare the resulting test RMSE with Task3. [15 pts] </h4>\n",
    "<h5> Result shows incooperating with rg,ri,rj would increase the prediction accuracy, comparing to GSD algorithm without bias loss correction. norm(ri) and norm(rj) work as a circle that regulate the loss function gradually reduce to within the circle thus to increase the prediction accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5e9004fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " when k =  4  RMSE of validation dataset is : 1.244\n",
      " when k =  8  RMSE of validation dataset is : 1.27\n",
      " when k =  16  RMSE of validation dataset is : 1.314\n",
      " The best RMSE is:  1.244  when K =  4\n"
     ]
    }
   ],
   "source": [
    "## modified SGD only print the final RMSE\n",
    "def SGD_bias(R,K = 8, lr = 0.01, lamda1 =0.3, lamda2=0.3,lamda3 =0.3,lamda4=0.3, epoch = 10 ): # R:csc sparse matrix; K:latent factor, lr: learning rate, lamda1 lamda2: hyperparameters\n",
    "    #  Latent Factor matrix shape\n",
    "    M,N = R.shape\n",
    "    bg = R.sum()/R.count_nonzero()\n",
    "    bj_val = (R.sum(axis =0)/R.astype(bool).sum(axis=0).sum()).T\n",
    "    bi_val = R.sum(axis =1)/R.astype(bool).sum(axis=1).sum()\n",
    "    bi = np.asarray(bi_val).reshape((M,1))\n",
    "    bj = np.asarray(bj_val).reshape((N,1))    \n",
    "    # get rows,columns,values of non-zero values\n",
    "    rows,columns,values = sparse.find(R) \n",
    "    # using random values of Q and P \n",
    "    Q=np.random.normal(0, 0.2, M*K).reshape((M,K)) # user factor matrix\n",
    "    P=np.random.normal(0, 0.1, N*K).reshape((N,K)) # business factor matrix\n",
    "    for e in range(0,epoch):\n",
    "        for i,j,v in zip(rows, columns, values): # for each rating of user i and business j\n",
    "            r_hat = np.dot(Q[i,:],P[j,:])           # get rating prediction\n",
    "            ## calculate loss function for Q,P, bi and bj\n",
    "            for f in range(0,K):\n",
    "                loss_q = -2*(v - r_hat-bg-bi[i,0]-bj[j,0])*P[j,f] + 2*lamda1 * Q[i,f]\n",
    "                loss_p = -2*(v - r_hat-bg-bi[i,0]-bj[j,0])*Q[i,f] + 2*lamda2 * P[j,f]\n",
    "                loss_bi = -2*(v - r_hat-bg-bi[i,0]-bj[j,0]) + 2*lamda3 * bi[i,0]\n",
    "                loss_bj = -2*(v - r_hat-bg-bi[i,0]-bj[j,0]) + 2*lamda4 * bj[j,0]\n",
    "                Q[i,f] -= lr * loss_q\n",
    "                P[j,f] -= lr * loss_p\n",
    "                bi[i,0] -= lr* loss_bi\n",
    "                bj[j,0] -= lr* loss_bj\n",
    "    return(Q,P,bi,bj,bg)\n",
    "\n",
    "## calculate RMSE on validation data for k = [4,8,16] to choose the best k at minimum RMSE\n",
    "result =[]\n",
    "for i in [4,8,16]:\n",
    "    result.append(i)\n",
    "    sgdmatrix = SGD_bias(csc_train, K = i)\n",
    "    RMSE = RMSE_bias(csc_val,sgdmatrix[0],sgdmatrix[1],sgdmatrix[4],sgdmatrix[2],sgdmatrix[3])\n",
    "    result.append(RMSE)\n",
    "    print(\" when k = \", i, \" RMSE of validation dataset is :\" , round(RMSE,3))\n",
    "result_RMSE = np.asarray(result).reshape((3,2))\n",
    "best_k = int(np.squeeze(result_RMSE[np.where(result_RMSE[:,1] ==result_RMSE[:,1].min(axis=0)),0]).item())\n",
    "print(\" The best RMSE is: \", round(result_RMSE[:,1].min(axis=0),3), \" when K = \", best_k )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc02b68",
   "metadata": {},
   "source": [
    "<h5> Final RMSE shows the training error after 10 epoches, RMSE shows the validation error at k = 4,8 and 16. Results show the error is minimum at k equals to 4. Hence we use K =4 for computing test errors.</h5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b43dd990",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " RMSE on test data is:  1.231\n"
     ]
    }
   ],
   "source": [
    "## calculate RMSE on test data for k = best_k\n",
    "sgdbias_test =SGD_bias(csc_train, K = best_k)\n",
    "RMSE_test = RMSE_bias(csc_test,sgdbias_test[0],sgdbias_test[1],sgdbias_test[4],sgdbias_test[2],sgdbias_test[3])\n",
    "print(\" RMSE on test data is: \", round(RMSE_test,3))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
